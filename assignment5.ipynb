{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c58e4e48-ba02-4991-91a7-31f439eef6d5",
   "metadata": {},
   "source": [
    "# Week 6 - Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6808410f-cd05-4733-bd81-d6cf04ea8ea9",
   "metadata": {},
   "source": [
    "The goal of this assignment is to test and compare some simple deep learning architectures for the problem of image classification. We will be using the Tensorflow framework.\n",
    "The CIFAR-10 dataset contains 60000 images divided into 10 classes. The set is split in 50000 and 10000 samples for the training and testing set, respectively. The tutorial found at [https://www.tensorflow.org/tutorials/images/cnn] gives a good introduction to this practical exercise. The essential code for this tutorial can be found in the provided script 'ConvNet.py' or as a Jupyter notebook in [https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/images/cnn.ipynb]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310d5eb4-bfc5-48b8-a245-04e25fb96cc0",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37fee738-c968-4c9c-8eb8-52982447b96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models, regularizers\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ee1941-eead-4f25-9af9-bc345432e0df",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5166c142-852a-43a4-b20f-f74b80f50df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 578s 3us/step\n",
      "170508288/170498071 [==============================] - 578s 3us/step\n"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a7f000-d968-46b1-bf8d-d65022dd627c",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fa1fe5-a066-42d5-8e39-d3045e218370",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(10, activation='softmax')])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_images, train_labels, epochs=50,\n",
    "                    validation_data=(test_images, test_labels))\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207bcac2-a421-4357-81c9-7e8a7d2122ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'], label='accuracy')\n",
    "plt.plot(history.history['val_acc'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1265770-f6ad-4989-8d0e-23809f65d882",
   "metadata": {},
   "source": [
    "## ConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fbb1e1-ee88-46c4-b36f-bb74417dd91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bf6056-0d6c-441f-945d-2407352da50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'], label='accuracy')\n",
    "plt.plot(history.history['val_acc'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37ab09b-1378-4263-88c9-47b4274f8d53",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "Modify the provided MLP model. Use architectures with 0, 1 and 2 hidden layers. Keep the complexity of the model bounded, so runs do not take much more than 1 hour to reach the maximum of testing accuracy. Notice that the input needs to be \"flattened\", since there is no spatial structure \n",
    "in this fully connected design. This can be achieved by adding a dummy layer with no free parameters with \"layers.Flatten()\" as the first layer in the constructor \"model.Sequential()\". Obtain the learning curves and discuss the results.\n",
    "Report the optimizer in use, initialization parameters, the learning rate, etc. Is early stopping convenient in this model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b096d6-32cc-4a34-89b0-c2d415d9a66f",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "Reuse the code from Exercise 1 to build and run an MLP with one hidden layer, as big a you can. Compare the performance of your design with the results appearing in Table 1 of [https://arxiv.org/pdf/1611.03530.pdf] for an MLP of 512 units in a single hidden layer. Report the best result found for a maximum of 1000 epochs or 2 hours CPU running time.\n",
    "The best accuracy amongst all teams will be awarded extra points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25224b48-76fd-4ef6-81d9-9b8fcc12b5dd",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "Study the performance properties of the convolutional network provided. How is the learning affected if instead of ReLU units, tanh() activations are used? What is the reason for this? Compare also at least two different optimizer algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f41d547-c3c6-4338-8cba-1cf3ec170918",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "\n",
    "Try to outperform the convolutional network from Exercise 3 with an MLP that uses approximately the same number of parameters.\n",
    "Report your results and explain them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792bc9e4-f2fd-457c-b96d-08fb95d4d303",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
